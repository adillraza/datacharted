"""Add GCP folder fields to User model

Revision ID: 256477559665
Revises: a1b2c3d4e5f6
Create Date: 2025-09-06 00:26:06.467062

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '256477559665'
down_revision = 'a1b2c3d4e5f6'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('bigquery_projects',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('project_id', sa.String(length=128), nullable=False),
    sa.Column('project_name', sa.String(length=256), nullable=False),
    sa.Column('project_number', sa.String(length=64), nullable=True),
    sa.Column('project_type', sa.String(length=20), nullable=True),
    sa.Column('billing_account_id', sa.String(length=128), nullable=True),
    sa.Column('default_dataset', sa.String(length=128), nullable=True),
    sa.Column('location', sa.String(length=32), nullable=True),
    sa.Column('service_account_email', sa.String(length=256), nullable=True),
    sa.Column('service_account_key_path', sa.String(length=512), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.Column('deleted_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['user.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('bigquery_projects', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_bigquery_projects_project_id'), ['project_id'], unique=True)

    op.create_table('data_sources',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('bigquery_project_id', sa.Integer(), nullable=True),
    sa.Column('source_type', sa.String(length=50), nullable=False),
    sa.Column('source_name', sa.String(length=256), nullable=False),
    sa.Column('connection_config', sa.JSON(), nullable=True),
    sa.Column('airbyte_source_id', sa.String(length=128), nullable=True),
    sa.Column('airbyte_connection_id', sa.String(length=128), nullable=True),
    sa.Column('sync_frequency', sa.String(length=32), nullable=True),
    sa.Column('sync_enabled', sa.Boolean(), nullable=True),
    sa.Column('last_sync_at', sa.DateTime(), nullable=True),
    sa.Column('next_sync_at', sa.DateTime(), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['bigquery_project_id'], ['bigquery_projects.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['user.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('vps_instances',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('bigquery_project_id', sa.Integer(), nullable=True),
    sa.Column('droplet_id', sa.String(length=128), nullable=True),
    sa.Column('droplet_name', sa.String(length=256), nullable=False),
    sa.Column('public_ip', sa.String(length=45), nullable=True),
    sa.Column('private_ip', sa.String(length=45), nullable=True),
    sa.Column('region', sa.String(length=32), nullable=True),
    sa.Column('size', sa.String(length=32), nullable=True),
    sa.Column('airbyte_workspace_id', sa.String(length=128), nullable=True),
    sa.Column('airbyte_url', sa.String(length=512), nullable=True),
    sa.Column('airbyte_username', sa.String(length=128), nullable=True),
    sa.Column('airbyte_password', sa.String(length=128), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.Column('deleted_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['bigquery_project_id'], ['bigquery_projects.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['user.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('vps_instances', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_vps_instances_droplet_id'), ['droplet_id'], unique=True)

    with op.batch_alter_table('user', schema=None) as batch_op:
        # Add new columns
        batch_op.add_column(sa.Column('gcp_folder_id', sa.String(length=128), nullable=True))
        batch_op.add_column(sa.Column('gcp_folder_name', sa.String(length=256), nullable=True))
        
        # Check and drop columns only if they exist
        inspector = sa.inspect(op.get_bind())
        existing_columns = [col['name'] for col in inspector.get_columns('user')]
        
        columns_to_drop = ['vps_id', 'ghl_connected', 'bigquery_project_id', 
                          'google_ads_connected', 'meta_ads_connected', 
                          'bigquery_dataset', 'callrail_connected', 'vps_ip']
        
        for column in columns_to_drop:
            if column in existing_columns:
                batch_op.drop_column(column)

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('user', schema=None) as batch_op:
        batch_op.add_column(sa.Column('vps_ip', sa.VARCHAR(length=45), nullable=True))
        batch_op.add_column(sa.Column('callrail_connected', sa.BOOLEAN(), nullable=True))
        batch_op.add_column(sa.Column('bigquery_dataset', sa.VARCHAR(length=128), nullable=True))
        batch_op.add_column(sa.Column('meta_ads_connected', sa.BOOLEAN(), nullable=True))
        batch_op.add_column(sa.Column('google_ads_connected', sa.BOOLEAN(), nullable=True))
        batch_op.add_column(sa.Column('bigquery_project_id', sa.VARCHAR(length=128), nullable=True))
        batch_op.add_column(sa.Column('ghl_connected', sa.BOOLEAN(), nullable=True))
        batch_op.add_column(sa.Column('vps_id', sa.VARCHAR(length=128), nullable=True))
        batch_op.drop_column('gcp_folder_name')
        batch_op.drop_column('gcp_folder_id')

    with op.batch_alter_table('vps_instances', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_vps_instances_droplet_id'))

    op.drop_table('vps_instances')
    op.drop_table('data_sources')
    with op.batch_alter_table('bigquery_projects', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_bigquery_projects_project_id'))

    op.drop_table('bigquery_projects')
    # ### end Alembic commands ###
